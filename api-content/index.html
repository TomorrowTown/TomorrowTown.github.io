{"posts":[{"title":"记一次golang后台服务内存泄漏问题的排查","content":"0x00 某日我们用golang编写的后台的网关服务在使用机器人压测时出现了使用内存激增的问题(达到了6G......)，毫无疑问，内存泄露了。于是就需要利用go tool pprof进行苦逼的排查了...... 分析heap还是goroutine? 对于进程内存的分析，利用go tool pprof可以获得heap及goroutine的相关信息。那么到底是选择分析heap呢，还是goroutine呢？ 一句话结论：使用内存profiling并不能在多线程环境下排查出内存泄露的原因。 原因如下： 使用heap能获得内存分配的情况，可以具体到哪一行代码占用了过多的内存，因而可以纠正缺少对于性能考虑的编码问题。但是在多线程环境下，排除低性能编码的情况，heap得到的只是一个点，一个最终结果，一个表象。因为这一个内存占用高的代码可能被多个goroutine调用，仅用heap我们并不能找到是哪条goroutine路径造成的泄漏，找不到源头，就无法解决内存泄漏问题，因此我们将利用go tool pprof获取goroutine的profile文件去分析。俗话说的好，&quot;go服务器内存泄漏，十次有九次都是协程泄漏&quot;，所以排查的重点自然也应首先放在对于goroutine的排查上。 那么什么是goroutine泄漏？还是一句话总结：该退出的协程没退出，被阻塞了，就是协程泄漏。 分析goroutine的profile文件 后台服务开启pprof的具体方法在此省略。 1. 获取goroutine的profile文件 在启动后台服务，启动压测机器人一小段时间之后，输入： go tool pprof http://localhost:9900/debug/pprof/goroutine 获得此时的goroutine profile文件，将其作为后续比较的基准文件。输入top指令可以得到持有goroutine数量最多的10个协程从高到低的序列，如下： 接下来去喝杯茶或者带薪拉屎...... 回来之后再次输入： go tool pprof http://localhost:9900/debug/pprof/goroutine 继续top，得到： 好家伙，我他妈直接好家伙，才一泡屎的功夫，网关的协程数量就多了快300个(前提是压测机器人仅启动了十个，并且每个机器人也只发少量的rpc请求)，协程泄漏无疑了。 2. 比较两个时间点的goroutine的profile文件 在获得以上两个goroutine的profile文件的基础上，输入： go tool pprof -base 基准profile文件名 第二个较新的profile文件名 得到： 再输入traces得到第二个profile比第一个profile多出来的协程调用栈： 这里只有一个调用栈，而多出来的280个协程也正好在这个调用栈中。 在这个调用栈里面runtime.gopark这样的系统调度方法不用管，我们找自己项目里的方法，sync.(*Cond).Wait是我们项目的代码，所以输入list Wait(list支持模糊查询)命令，进去该方法内部看看： 找到项目代码里的部分，我们可以看到这280个协程阻塞在了waitForMsgs里的**s.pCond.Wait()**里了，这属于我们项目使用的mq代码。 阻塞大量协程的地方找到了，接下来就是进入到mq及项目的源码去具体分析为什么会阻塞在这里了。 nats reply subscribe接收过程 上面我们定位到了是waitForMsgs()里的s.pCond.Wait()阻塞了协程。这属于我们项目使用的开源消息中间件NATS中的代码。 waitForMsgs()中的注释如下： 由此可知该方法是用于传递消息给我们的异步sub的。 继续看waitForMsgs()的源码，如下(由于这个函数实在太多行了，所以只看最关键的for循环~)： 由以上代码可知s.pCond.Wait()是在等待其他服务向我们的sub去pub消息的，如果一直没有消息pub过来，就会一直在这里Wait，break这个for循环的条件有两个，一个是waitForMsgs()的参数Subscription的closed变量为true，另一个是达到了消息传递上限。 从源码中我并没有发现对于sub的等待超时机制，所以这个for必定不会因为超时(长时间收不到pub的消息)而将closed置为true，从而将for循环break，其实对于pub/sub模型下的mq，不做超时机制这也可以理解的；同理，如果长时间收不到对应的sub，那么for循环也不会因为达到了消息传递上限而break。由此可知，如果一个错误的sub被加载到nats-client，则会导致这个for循环长期阻塞在s.pCond.Wait()。 从waitForMsgs的Usage可以看到，它是被subscribeLocked()方法调用的： 由上图可知，每个subscribe()的调用都会go一个**waitForMsgs()**协程用于回调我们注册的方法，**subscribeLocked()又是被subscribe()**调用的，**subscribe()又被我们自己写的gateserver调用。 这样就能解释为什么gateserver的内存会泄露了，以及为什么会在s.pCond.Wait()**处阻塞大量协程了， 根本原因是NATS在nats-client sub了之后会在一个无法满足退出条件的for循环中Wait其对应的pub，且由于pub/sub模型的需要，并没有一个超时机制去清除长时间没被pub的sub。既然NATS是这么设计的，而且是合理的设计，那么出问题的只能是我们自己了...... : ( 所以导致goroutine泄漏的原因就是我们进行了错误的sub。怎么个错误法，可能的原因有两个： 我们sub了一个没有任何服务去处理的topic； 由于NATS是根据key去查找sub的，所以有可能是我们在添加KV pair时部分key是重复的，导致NATS 在pub消息时总是只能传递到所有重复key的sub的其中一个sub，进而导致其他重复key的sub始终没有收到pub的消息，从而导致它们被阻塞，且随着时间的推移，sub的次数越来越多，阻塞的goroutine也越来越多...... 压测机器人是定时发送一批sub的，假如一次分别sub的是A，B，C三个主题，而在gateserver中我们维护的sub map在add时没处理好，使得B和C拥有了相同的key，那么在B和C之中永远有一个永远收不到pub的消息，而压测机器人又在不停地sub A、B、C...... 对于第一个可能，其实是不可能的，因为对于pub/sub模型，我们针对的是“服务(Service)”这个粒度的发布和推送，而不是“方法(Method)”这个粒度的发布和推送，所以不可能是“方法”不对导致的收不到pub消息，所以没必要再画蛇添足增加对于“方法”的鉴权了(我最初就画蛇添足了，结果导致许多服务都不能用了......)。而在我们的gateserver中已经有了对于“服务”sub的鉴权了，所以在gateserver中不存在客户端能够sub一个不存在的“服务”的情况。 那么就只剩下上述第二种情况了......经查，果然是...... 每次往gateserver维护的sub map添加KV时，把原来会重复的key换成唯一key就好了...... 真傻逼的错误啊...... ","link":"https://TomorrowTown.github.io/post/golang-service-memory-leak-solve/"},{"title":"Go语言并发编程模型(九) -- context","content":"0x00 在Go1.7发布时，标准库增加了一个context包，用来简化对于处理单个请求的多个goroutine之间与请求域的数据、超时和退出等操作。 context包的应用 1. 线程安全退出和超时控制 // when the concurrent body timeout or 'main' actively stops the worker goroutine, each worker can safely exit func worker(ctx context.Context, wg *sync.WaitGroup) error { defer wg.Done() for { select { case &lt;- ctx.Done(): // exit return ctx.Err() default: fmt.Println(&quot;doing work...&quot;) } } } func main() { ctx, cancelFunc := context.WithTimeout(context.Background(), time.Second * 10) wg := &amp;sync.WaitGroup{} for i := 0; i &lt; 10; i++ { wg.Add(1) go func() { err := worker(ctx, wg) fmt.Println(&quot;err = &quot;, err) }() } time.Sleep(time.Second) cancelFunc() wg.Wait() } 2. 防止后台goroutine内存泄漏 虽然go语言自带垃圾回收，一般不会发生内存泄漏，但当main函数不再使用channel时，后台goroutine有泄漏风险。使用context包可以避免这样的情况发生(不需要使用sync.WaitGroup了)。例： func worker(ctx context.Context) error { for { select { case &lt;- ctx.Done(): // exit return ctx.Err() default: fmt.Println(&quot;doing work...&quot;) } } } func main() { ctx, cancelFunc : = context.WithCancel(context.Background()) wg := &amp;sync.WaitGroup{} for i := 0; i &lt; 10; i++ { go func() { err := worker(ctx) }() } /* * when the main function completes its work, it will calls cancelFunc() first, * to notify the background Goroutine to exit, * thus avoiding the leakage of Goroutine. */ cancelFunc() } References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-9-golang-basics-context/"},{"title":"Go语言并发编程模型(八) -- 并发的安全退出","content":"0x00 当select有许多分支时，会随机选择一个可用的channel分支，若没有可用channel分支，则default分支将会被选择，否则会一直保持阻塞状态。 select语句的应用 1. 超时判断 // choose one of the two, without default, either perform &quot;&lt;- in&quot; or timeout(channel is still empty after one second) select { case v := &lt;- in: // do something... case &lt;- time.After(time.Second): // timeout, return return } 2. 非阻塞channel的发送和接收操作 select { case v := &lt;- in: // do something default: // there is no data in channel } 3. 阻止main函数退出 func main() { // do something select {} // keep blocking here } 4.生成随机数序列 当有多个channel可用时， select会随机选择一个可用的channel。基于此特性，我们可以实现一个随机数序列生成程序： func main() { ch := make(chan int) go func() { for { select { case ch &lt;- 0: case ch &lt;- 1: } } }() for v := range ch { // random output 0 and 1 fmt.Println(v) } } 5.协程退出控制 (1) 关闭一个goroutine func worker(cancel chan bool) { for { select { case &lt;- cancel: // exit fmt.Println(&quot;stop work...&quot;) return default: // do something... fmt.Println(&quot;doing some work...&quot;) } } } func main() { cancel := make(chan bool) go worker(cancel) time.Sleep(time.Second) cancel &lt;- true // notify goroutine quit } (2) 关闭多个goroutine 使用**close()**方法关闭channel，使其达到广播的效果，select的所有接收channel分支都会在channel关闭时收到0值。 func worker(cancel chan bool) { for { select { case v := &lt;- cancel: // exit fmt.Println(&quot;stop work... v = &quot;, v) return default: fmt.Println(&quot;doing work...&quot;) } } } func main() { cancel := make(chan bool) go worker(cancel) time.Sleep(time.Second) close(cancel) } NOTE: 由于goroutine在收到退出指令进行退出时会执行一定的清理工作，但是上述程序并不能够保证清理一定能够完成，所以为了保证程序的健壮性，我们需要使用sync.WaitGroup，以求main线程能够等待各个goroutine退出完成。 References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-09-golang-basics-concurrent-exit-safely/"},{"title":"Go语言并发编程模型(七) -- 控制并发数","content":"控制并发数的意义 适当地控制并发数，能够为其他程序提供可供使用的CPU资源，也可以节省能耗。 对于细粒度的并发程序而言，CSP模型中的消息传递机制的开销是非常大的(多线程并发模型不可避免地会面对线程启动的开销)。 使用有缓冲channel实现groutine的并发数控制 一个简单的示例： package main import ( &quot;fmt&quot; &quot;runtime&quot; &quot;sync&quot; ) var ch chan bool func worker() { fmt.Println(&quot;test&quot;) &lt;- ch } func main() { wg := &amp;sync.WaitGroup{} ch = make(chan bool, 10) for i := 0; i &lt; 1000; i++ { wg.Add(1) ch &lt;- true go worker() wg.Done() } fmt.Println(&quot;runtime goroutine num = &quot;, runtime.NumGoroutine()) wg.Wait() } 这样，同时运行的goroutine就控制在了10个。 References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-09-golang-basics-control-the-number-of-concurrent/"},{"title":"Go语言并发编程模型(六) -- 发布订阅模型","content":"0x00 相比于生产者消费者模型而言，消息的生产者在发布订阅模型中充当了消息的发布者(publisher)，消息的消费者充当了消息的订阅者(subscriber)。 在传统的生产者消费者模型中，消息被发送到一个队列中，而在发布订阅模型中，消息被发布给一个主题(topic)。 在发布订阅模型中，每一个消息都被传递给多个订阅者。发布者通常不知道也不关心哪个订阅者收到了主题消息。发布者和订阅者可以在运行时动态地添加，是一种松散的耦合关系，这使得系统地复杂性会随着时间的推移而增长。 一个支持多主题的pub-sub库的简易实现 package main import ( &quot;fmt&quot; &quot;strings&quot; &quot;sync&quot; &quot;time&quot; ) type ( // subscriber is a channel subscriber chan interface{} topicFunc func(v interface{}) bool ) // the publisher object type Publisher struct { m sync.RWMutex buffer int // the cache size of subscription queue timeout time.Duration // publish timeout subscribers map[subscriber]topicFunc // subscriber information } func NewPublisher(timeout time.Duration, buffer int) *Publisher { return &amp;Publisher { buffer: buffer, timeout: timeout, subscribers: make(map[subscriber]topicFunc), } } // add a new subscriber, subscribes all topic func (p *Publisher) Subscribe() chan interface{} { return p.SubscribeTopic(nil) } // add a new subscriber, subscribes the topic filtrated by filter func (p *Publisher) SubscribeTopic(topic topicFunc) chan interface{} { ch := make(chan interface{}, p.buffer) p.m.Lock() p.subscribers[ch] = topic p.m.Unlock() return ch } func (p *Publisher) Exit(sub chan interface{}) { p.m.Lock() defer p.m.Unlock() delete(p.subscribers, sub) close(sub) } // publish a topic func (p *Publisher) Publish(v interface{}) { p.m.RLock() defer p.m.RUnlock() var wg sync.WaitGroup for sub, topic := range p.subscribers { wg.Add(1) go p.SendTopic(sub, topic, v, &amp;wg) } // wait for all goroutines excute finish wg.Wait() } // close publisher object, at the same time, close all the channel of subscribers func (p *Publisher) Close() { p.m.Lock() defer p.m.Unlock() for sub := range p.subscribers { delete(p.subscribers, sub) close(sub) } } // send topic, can tolerate a certain timeout func (p *Publisher) SendTopic(sub subscriber, topic topicFunc, v interface{}, wg *sync.WaitGroup) { defer wg.Done() if topic != nil &amp;&amp; !topic(v) { return } select { case sub &lt;- v: // ...... case &lt;- time.After(p.timeout): // ...... } } // test code ... func main() { p := NewPublisher(time.Millisecond * 100, 10) defer p.Close() all := p.Subscribe() gTopic := p.SubscribeTopic(func(v interface{}) bool { if s, ok := v.(string); ok { return strings.Contains(s, &quot;golang&quot;) } return false }) // pub p.Publish(&quot;hello world!&quot;) p.Publish(&quot;hello golang!&quot;) // sub go func() { for msg := range all { fmt.Println(&quot;all: &quot;, msg) } }() go func() { for msg := range gTopic { fmt.Println(&quot;golang: &quot;, msg) } }() // exit after a certain time time.Sleep(time.Second * 3) } References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-08-golang-basics-publish-and-subscribe-model/"},{"title":"Go语言并发编程模型(五) -- 生产者消费者模型","content":"talk is cheap, show you the code: // producer: generate a sequence of multiples of factor func Producer(factor int, out chan &lt;- int) { for i := 0; ; i++ { out &lt;- i * factor } } // consumer func Consumer(in &lt;- chan int) { for v := range in { fmt.Println(v) } } func main() { ch := make(chan int, 64) // result queue // the producers below are concurrency, therefore, the order of the result sequence output by the consumer is uncertain go Producer(3, ch) // generate a sequence of multiples of 3, and put them into the ch go Producer(5, ch) // generate a sequence of multiples of 5, and put them into the ch go Consumer(ch) // consume the generated sequence // exit after a certain time, let producers and consumers work for a certain time // time.Sleep(time.Second * 5) /* * but the above sleep mode cannot guarantee stable output, * so we can let the main function save the blocked state without exiting * and only exit the program when the user enters &quot;Ctrl C&quot; */ sig := make(chan os.Signal, 1) signal.Notify(sig, syscall.SIGINT, syscall.SIGTERM) fmt.Println(&quot;quit (%v)\\n&quot;, &lt;- sig) } References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-07-golang-basics-producer-and-consumer-model/"},{"title":"Go语言并发编程模型(四) -- 基于管道的通信","content":"0x00 依靠channel通信是不同goroutine之间同步的主要方法。 无缓冲channel 对于无缓冲channel而言，每一个发送操作(chan &lt;- x)都对应一个接收操作(&lt;- chan)，反之亦然。channel的发送和接收操作通常出现在不同的goroutine之间，如果放到同一个goroutine，则很容易出现死锁问题。 使用示例： var done = make(chan bool) // define an unbuffered channel, its len and cap always equal to 0 var msg string func aGoroutine() { msg = &quot;hello world&quot; done &lt;- x // sending operation, send a synchronization signal to channel // or use close(done) to replace done &lt;- false } func main() { go aGoroutine() &lt;- done // receiving operation, receive the corresponding synchronization signal fmt.println(msg) } 有缓冲channel 通过有缓冲channel的buffer大小，我们可以控制并发执行的goroutine的最大数量。例： var limit = make(chan int, 3) // the channel with cache, length can be 0, 1, 2 or 3, capacity equals to 3 func main() { for _, w := range workerThread { go func() { limit &lt;- 1 w() &lt;- limit }() select{} // empty pipeline selcetion statement, means that only the channel be nil, the main thread can excute return } } 上述程序允许的最大并发数为3。 Summary： 无缓冲channel：如果线程A向channel进行写操作，线程B尚未对该channel进行读操作，那么A线程将会被阻塞在写操作语句。相应的，如果线程A对一个线程进行读操作，线程B尚未对channel进行写操作，那么A线程将会阻塞在读操作语句。 有缓冲channel：只有当该channel的len==cap时，即该channel满了时，向该channel再进行写操作的化，写操作语句就会被阻塞。如果该channel中无数据(即len=0)，那么读该channel的语句将会被阻塞。 无缓冲channel：实现线程间同步。 有缓冲channel：线程间是异步的。 注意：如果对channel的读和写操作在同一个线程中进行，那么很容易造成读写互相等待，即死锁。 References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-04-golang-basics-channel-based-communication/"},{"title":"Go语言并发编程模型(三) -- 顺序一致性内存模型","content":"0x00 原子操作能够为线程之间的数据同步提供部分保证的前提是顺序一致性内存模型。 线程间同步的本质就是为并发的事件进行排序。 以下为一个顺序一致性内存模型： var a string var done bool func set() { a = &quot;hello world&quot; done = true } func main() { go set() for !done {} fmt.Println(a) } 在Go语言中，在同一个goroutine内的内存顺序模型能够得到保证(在本例中即：go set()中的a赋值语句一定先于done赋值语句执行)。但是在不同的goroutine中，内存模型的顺序就不能单纯地通过书写顺序去保证了。假如在main线程书写一个done赋值语句，那么就无法保证go set()协程的done赋值语句和main线程的done赋值语句谁先执行了，那么print出来的a就可能为空。 这是因为在Go中，为了使并行最大化，go的编译器和处理器会对语句进行重排，同时CPU也可能会对指令集进行重排。更糟糕的是，main线程可能无法察觉到set协程中的变量变化(可能始终在寄存器内)，进而导致main线程死循环。如果并发程序不能确定事件发生的顺序，那么输出的结果也是不确定的，如以下这个程序： func main() { go fmt.Println(&quot;hello world&quot;) } 由于goroutine和return事件是并发的，这两个事件谁都可能先发生，最终是否能打印出hello world也是无法确定的。 使用同步原语进行同步 func main() { done := make(chan int) go func() { fmt.Println(&quot;111&quot;) done &lt;- 1 // 同步语句 1 }() &lt;- done // 同步语句2 fmt.Println(&quot;222&quot;) } done &lt;- 1：向channel传值；&lt;- done：从channel取值。 向channel传值取值先写谁都无所谓，因为传了没人取，和想取没人传，都会使channel阻塞， 因此同步语句2能够顺利执行(不阻塞)，就意味着同步语句1肯定执行了，又因为在一个goroutine中总能保证顺序一致性内存，因此在语句1执行之前，&quot;111&quot;肯定打印了，因此总能保证先打印&quot;111&quot;，再打印&quot;222&quot;。 使用互斥量实现同步 func main() { var mu sync.Mutex mu.Lock() go func() { fmt.Println(&quot;hello world&quot;) mu.Unlock() }() mu.Lock() } 一个goroutine内的语句能够保证顺序一致性内存，所以打印语句必发生在Unlock()之前；在main线程中，先执行了第一个Lock()，那么通过sync.Mutex内部的保证，第二个Lock()必发生在goroutine中的Unlock()之后。因此能够保证该程序正常输出hello world。 References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-03-golang-basics-sequential-consistency-memory-model/"},{"title":"Go语言并发编程模型(二) -- 原子操作","content":"使用互斥锁实现原子操作 通常，原子操作由“互斥”访问保证，通常由特殊的CPU指令保护。当然，如果只是想模拟粗粒度的原子操作，我们可以使用sync.Mutex来做到这一点。 package main import ( &quot;sync&quot; &quot;fmt&quot; ) var total struct { sync.Mutex value int } func worker(wg *sync.WaitGroup) { defer wg.Done() for i := 0; i &lt; 100; i++ { total.Lock() total.value += 1 total.Unlock() } } func main() { var wg sync.WaitGroup wg.Add(2) go worker(&amp;wg) go worker(&amp;wg) wg.Wait() fmt.Println(total.value) // 10100 } 使用sync/atomic实现原子操作 如上，使用互斥锁去保护数字共享资源既麻烦又低效。标准库中的sync/atomic包对此提供了丰富的支持。利用此包重新实现上面的例子： package main import ( &quot;sync&quot; &quot;sync/atomic&quot; &quot;fmt&quot; ) var total uint64 func worker(wg *sync.WaitGroup) { defer wg.Done() for i := 0; i &lt;= 100; i++ { atomic.AddUnit64(&amp;total, i) } } func main() { var wg sync.WaitGroup wg.Add(2) go worker(&amp;wg) go worker(&amp;wg) wg.Wait() fmt.Println(total.value) // 10100 } 利用原子操作和互斥锁实现单例 原子操作和互斥锁可以实现非常高效的单例模式。互斥锁的开销比普通整数的原子读写要高得多。 在性能敏感的地方可以增加一个数字型的标志位，通过原子检测标志位状态降低互斥锁的使用次数来提高性能。 type singleton struct {} var ( instance *singleton initialized uint32 mu sync.Mutex ) func GetInst() *singleton { if atomic.LoadUint32(&amp;initialized) == 1 { return instance } mu.Lock() defer mu.Unlock() if instance == nil { defer atomic.StoreUint32(&amp;initialized, 1) instance = &amp;singleton {} } return instance } 将上例中的公共部分提取出来就是标准库中的 sync.Once包。sync.Once源码如下所示： type Once struct { m mutex done uint32 } func (o *Once) Do(f func()) { if atomic.LoadUint32(&amp;o.Done) == 1 { return } o.m.Lock() defer o.m.Unlock() if o.done == 0 { defer atomic.StoreUint32(&amp;o.done, 1) f() } } 现在，基于sync.Once重新实现单例模式： var ( instance *singleton once sync.Once ) func GetInst() *singleton { once.Do(func() { instance = &amp;singleton{} }) return instance } Load &amp; Store atomic.Value对象提供了Load和Store两种方法，用于加载和保存数据。其返回值和参数均为**interface{}**类型，所以这两种方法可以用于自定义的任何复杂结构。 /* This is a simplified producer-consumer model: back-end thread generate the latest configuration; multiple worker threads in the front-end get the latest configuration. All threads share configuration resources. */ // save the current configuration var conf atomic.Value // initialize the configuration conf.Store(loadConfig()) // start a backend thread, load the updated configuration go func() { for { time.Sleep(time.Second) conf.Store(loadConfig()) } } // the worker threads used to process requests, always use the latest configuration for i := 0; i &lt; 10; i++ { go func() { for r := range requests() { c := conf.Load() } }() } References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-02-golang-basics-atomic-operation/"},{"title":"Go语言并发编程模型(一) -- 开篇","content":"0x00 首先看一下并发与并行的区别： 并发：注意力更多地集中于设计层面，并发程序能够被顺序执行； 并行：注意力更多地集中于运行层面，并发程序一般是大量简单重复的运算。 在早期，CPU在一个单核中顺序地执行机器指令，所以早期地编程语言是一种顺序地编程语言：所有地指令都以串行地方式执行。当单核CPU的频率达到极限时，就会出现多核处理器，相应的，编程语言也需要朝着并行的方向发展。 在并发编程中，对资源的精确访问需要精确的控制。在大多数语言中，这个困难的问题是通过锁和其他同步解决方案来解决的。但在golang中有另一种方式，它将共享的值通过channel传递。在任何时刻，最好只有一个goroutine可以拥有该资源。数据竞争在设计层面被消除。 常用的并发编程模型有多线程模型、消息传递模型等。golang是基于消息并发实现其并发特性的，其将CSP并发编程模型内置到了语言中。与Erlang不同的是，golang的goroutine是由go这个关键字创建的共享内存。 Golang并发编程的slogan： Do not communicate by sharing memory; instead, share memory by communicating. go协程与系统线程 go协程(goroutine)是一种轻量级的线程。启动一个go协程，不仅简单如调用一个函数，而且启动的开销非常小，协程之间的调度成本也非常低。 go协程与系统线程的差别 go协程与系统线程的差别只是一个变量，但正是这个变量的区别导致了go并发编程的质的飞跃。 **系统级线程：**具有固定的栈大小(通常默认是2MB)，该栈主要用于在递归调用函数时保存参数和局部变量。固定栈大小会导致两个问题：一是对许多只需要少量栈空间的线程来说是一种巨大的浪费；二是需要大量栈空间的线程会面临栈溢出的风险。 **go协程：**goroutine以一个非常小的栈启动，栈大小不固定，可动态伸缩(最多为1GB)。因此启动成本非常小，所以可以启动成千上万个goroutine。 goroutine的调度器 goroutine采用半抢占式的协作调度，只有在当前goroutine被阻塞时才会导致调度。同时，它发生在用户模式下。调度器会根据具体函数只保存必要的寄存器，切换成本远低于系统线程。运行时有一个runtime.GOMAXPROCS变量，用于控制当前运行正常非阻塞Goroutine的系统线程数。 关于goroutine的调度器的详细说明请参阅：&lt;(https://tonybai.com/2017/06/23/an-intro-about-goroutine-scheduler/&gt; References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-12-01-golang-basics-introductory-remarks/"},{"title":"Go语言基础(四) -- 函数、方法和接口","content":"懒，所以还是贴笔记 0x00 There are named and anonymous functions in Go: named function generally correspond to package-level functions, which is a special case of anonymous function. When an anonymous function refers to a variable in an external scope, it becomes a closure function. Closure functions are the core of functional programming languages. Method(it is a kind of function) is special functions bound to a specific type. Method in Go are dependent on types and must be statically bound at compile time. The interface defines a set of methods, these methods rely on the interface object at runtime, so the corresponding method of the interface is dynamically bound at runtime. Go language implements duck object-oriented model through implicit interface mechanism. Feature 1-11 Package initial process It should be noted that before the main.main function is executed, all code runs in the same goroutine, which is the main system thread of the program. Therefore, if a new goroutine is started with the go keyword inside an init function, the new goroutine may only be executed after entering the main.main function. 1.3.1 Function In Go, function is first-class object, and we can keep function in variables. Functions are mainly divided into named and anonymous. Package-level functions are generally named functions. Named functions are a special case of anonymous functions // named function func Add(a, b int) int { return a + b } // anonymous function var Add = func(a, b int) int { return a + b } Functions in Go language can have multiple parameters and multiple return values. Both parameters and return values exchange data with the callee by value. Syntactically, the function also supports a variable number of parameters. The variable number of parameters must be the last parameter. The variable number of parameters is actually a slice type parameter. When the variable parameter is an empty interface type, whether the caller unpacks the variable parameter will cause different results: func main() { var a = []interface{}{123, &quot;abc&quot;} Print(a...) // 123 abc Print(a) // [123 abc] } func Print(a ...interface{}) { fmt.Println(a...) } You can modify the return value by name, or you can modify the return value after the return statement through the defer statement: func Inc() (v int) { defer func() {v++} () return 42 } /* finally, v will equals to 43 */ Among them, the defer statement delays the execution of an anonymous function, because this anonymous function captures the local variable v of the external function. Closures do not access captured external variables by value, but by reference. The behavior of accessing external variables by this reference method of closures may cause some hidden problems: func main() { for i := 0; i &lt; 3; i++ { defer func(){ println(i) } () } } // Output: // 3 // 3 // 3 Because it is a closure, in the for iteration statement, each defer statement delays the execution of a function that references the same i iteration variable. This variable has a value of 3 after the loop ends, so the final output is 3. The idea of the repair is to generate unique variables for each defer function in each iteration. You can use the following two methods(Generally speaking, it is not a good habit to execute defer statements inside a for loop. This is only an example and is not recommended): func main() { for i := 0; i &lt; 3; i++ { /*define a local variable i in a loop, In this way, the closure function of each iteration of the defer statement captures different variables */ i := i defer func(){ println(i) } () } } func main() { for i := 0; i &lt; 3; i++ { // pass in i through the function // the defer statement will immediately evaluate the call parameters defer func(i int){ println(i) } (i) } } The elements of the incoming slice can be modified inside the called function, which seems to violate the principle of passing parameter values to function of Go. In fact, any situation in which the call parameters can be modified through function parameters is because the function parameters have explicit or implicit incoming pointer parameters. The specification of the function parameter passing value is more accurately only for the fixed part of the data structure, such as the pointer in the corresponding structure of the string or slice and the value of the string length structure, but does not contain the content pointed by the pointer indirectly. Replace the slice type parameters with a structure similar to reflect.SliceHeader to understand the meaning of slice pass value: func twice(x []int) { for i := range x { x[i] *= 2 } } type IntSliceHeader struct { Data []int Len int Cap int } func twice(x IntSliceHeader) { for i := 0; i &lt; x.Len; i++ { x.Data[i] *= 2 } } Because the underlying array part of the slice is passed through an implicit pointer (the pointer itself is still passed by value), the called function can modify the data in the call parameter slice through the pointer. In addition to data, the slice structure also contains slice length and slice capacity information. These two pieces of information are also passed by value. If the Len or Cap information is modified in the called function, it cannot be reflected in the slice of the calling parameter. At this time, we generally update the previous slice by returning the modified slice. This is why the built-in append must return a slice. Go supports recursive calls. There is no limit to the recursive call depth of Go functions, that is, there is no limit to the size of the call stack, and there will be no overflow errors. This is because the Go function stack dynamically adjusts the size. Before Go1.4, the dynamic stack was a segmented stack implemented by linked list, and the node memory location of each linked list would not change. Since the memory locations of adjacent nodes are generally not adjacent, which increases the probability of CPU cache misses, the performance of hotspot calls across different nodes of the linked list is reduced. After Go1.4, a dynamic array-like structure was used to implement a continuous dynamic stack, which solved the shortcomings of the above segmented stack. But its disadvantage is that when the continuous dynamic stack grows, the previous data needs to be moved to a new memory space, which causes the addresses of all variables in the previous stack to change, so pointers in Go are no longer fixed.(that is, you cannot hold pointers for a long time in programming (this is different from C/C ++), although the Go runtime will automatically update the pointers that refer to the changed stack variables). The concept of stack and heap is not even mentioned in the Go language specification deliberately. We can't know whether the function parameters or local variables are stored on the stack or the heap, we just need to know that they can work properly. Consider the following example: func f(x int) *int { return &amp;x } func g() int { x = new(int) return *x } The first function directly returns the address of the function parameter variable-this seems impossible, because if the parameter variable is on the stack, the stack variable becomes invalid after the function returns, and the returned address should naturally also become invalid. But the Go compiler and runtime are much smarter than us, and it will ensure that the variables pointed to by the pointer are in the right place. The second function, although calling the new function internally creates a pointer object of type *int, but still does not know where it is stored. For programmers with C/C ++ programming experience, it is important to emphasize that: don't care about the function stack and heap problems in Go, the compiler and runtime will help us get it; also don't assume that the location of variables in memory is fixed, the pointer may change at any time, especially if you don't expect it to change. 1.3.2 Method Method is generally a feature of object-oriented programming (OOP). In the C ++ language, method correspond to member functions of a class object and is associated with virtual tables on specific objects. However, Go method is associated with type, so that static binding of methods can be done during the compilation phase. The method evolved from the function, just moved the first object parameter of the function to the front of the function name: type File struct { fd int } func OpenFile(name string) (f *File, err error) { // ... } /////////////////////////////////////// C-style File function /////////////////////////////////////// func CloseFile(f *File) error { // ... } func ReadFile(f *File, offset int64, data []byte) int { // ,,, } /////////////////////////////////////// Go OOP /////////////////////////////////////// func (f *File) Close() error { // ... } func (f *File) Read(offset int64, data []byte) int { // ... } We can still use the method according to the original procedural thinking. The method can be reduced to a normal type of function by calling the characteristics of the method expression: // not rely on the specific File object // func CloseFile(f *File) error var CloaseFile = (*File).Close // func ReadFile(f *File, offset int64, data []byte) int var ReadFile = (*File).Read f, _ := OpenFile(&quot;foo.dat&quot;) // need to pass the f parameter ReadFile(f, 0, data) CloseFile(f) In some scenarios, we are more concerned about a similar set of operations: for example, Read reads some arrays, and then calls Close to close. In this environment, the user does not care about the type of operation object, as long as it can meet the general Read and Close behavior. However, in the method expression, because the obtained ReadFile and CloseFile function parameters contain the unique type parameter of File, this makes the File-related methods not seamlessly compatible with other objects that are not of the File type but have the same Read and Close methods. We can eliminate the difference in the first parameter type in the method expression by combining closure characteristics: f, _ := OpenFile(&quot;foo.dat&quot;) // bind to f object // func Close() error var Close = func() error { return (*File).Close(f) } // bind to f object // func Read(offset int64, data []byte) int var Read = func(offset int64, data []byte) int { return (*File).Read(f, offset, data) } // do not need to pass the f parameter Read(0, data) Close() The method value characteristic can simplify the realization: f, _ := OpenFile(&quot;foo.dat&quot;) // method value: bind to f object // func Close() error var Close = f.Close // method value: bind to f object // func Read(offset int64, data []byte) int var Read = f.Read // do not need to pass the f parameter Read(0, data) Close() Go do not support the traditional OOP's inheritance, but use the combination to implement it. In Go, inheritance is achieved by building anonymous members in the structure: import &quot;image/color&quot; type Point struct{X, Y float64} type ColoredPoint struct { Point Color color.RGBA } // two ways to use var cp ColoredPoint cp.X = 1 fmt.Println(cp.Point.X) // &quot;1&quot; cp.Point.Y = 2 fmt.Println(cp.Y) // &quot;2&quot; By embedding anonymous members, we can also inherit the methods corresponding to anonymous member types. We generally regard Point as the base class, and ColoredPoint as its inherited class or subclass. However, the method inherited in this way cannot achieve the polymorphism of virtual functions in C++. The receiver parameter of all inherited methods is still the anonymous member itself, not the current variable. type Cache struct { m map[string]string sync.Mutex } func (p *Cache) Lookup(key string) string { p.Lock() // p.Mutex.Lock(), this expansion is done at compile time, and no runtime cost. defer p.Unlock() // p.Mutex.Unlock(), this expansion is done at compile time, and no runtime cost. return p.m[key] } If we need the polymorphism of virtual function, we need to use Go interface to achieve. 1.3.3 Interface Interface is also a type, and interface in Go is an abstraction and generalization of other types of behavior. Go is a strongly typed language. Implicit type conversion is not allowed between types(like int to int64, It is also impossible to assign a value of type int to a variable of the newly defined named type whose bottom type is int and so on), but interfaces are an exception. As long as an object implements a method of an interface, it can be regarded as the interface type. The interface type of Go language is lazy binding, which can realize polymorphism like virtual function, and implements the implicit duck object-oriented model. This design is especially flexible and useful when the types we use come from packages that are not under our control. For example, implement the custom Writer: // Go source code type io.Writer interface { Write(p []byte) (n int, err error) } // implement the custom Writer, convert each character to uppercase and output type UpperWriter struct { io.Writer } func (p *UpperWriter) Write(data []byte) (n int, err error) { return p.Writer.Write(bytes.ToUpper(data)) } func main() { fmt.Fprintln(&amp;UpperWriter{os.Stdout}, &quot;hello, world&quot;) // func Fprintf(w io.Writer, format string, args ...interface{}) (int, error) } Conversions between objects and interfaces, conversions between interfaces and interfaces may all be implicit conversions: var ( a io.ReadCloser = (*os.File)(f) // implicit conversion, *os.File satisfy io.ReadCloser interface b io.Reader = a // implicit conversion, io.ReadCloser satisfy io.Reader interface c io.Closer = a // implicit conversion, io.ReadCloser satisfy io.Closer interface d io.Reader = c.(io.Reader) // explicit conversion, io.Closer not satisfy io.Reader interface ) Limit the flexibility of interface adaptation A common practice is to define a special method to distinguish interfaces. For example, the Error interface in the runtime package defines a unique RuntimeError method to prevent other types from inadvertently adapting the interface: type runtime.Error interface { error // RuntimeError is a no-op function but // serves to distinguish types that are run time // errors from ordinary errors: a type is a // run time error if it has a RuntimeError method. RuntimeError() } In protobuf, the Message interface also adopts a similar method, and also defines a unique ProtoMessage to prevent other types from inadvertently adapting the interface: type proto.Message interface { Reset() String() string ProtoMessage() } But defining unique methods does not prevent others from forging this method. A stricter approach is to define a private method for the interface. Only objects that satisfy this private method may satisfy this interface, and the name of the private method contains the absolute path name of the package, so this interface can only be satisfied by implementing this private method inside the package. The testing.TB interface in the test package uses a similar technique: type testing.TB interface { Error(args ...interface{}) Errorf(format string, args ...interface{}) ... // A private method to prevent users implementing the // interface and so future additions to it will not // violate Go 1 compatibility. private() } However, this method of prohibiting external objects from implementing interfaces through private methods comes at a price: first, this interface can only be used internally by the package, and external packages cannot normally directly create objects that satisfy the interface; second, this protective measure also Not absolutely, malicious users can still bypass this protection mechanism. In the previous method section we talked about that, by embedding anonymous type members in the structure, you can inherit the anonymous type methods. In fact, the embedded anonymous member is not necessarily a common type, but also an interface type. We can forge a private private method by embedding an anonymous testing.TB interface. Because the interface method is delayed binding, it does not matter whether the private method really exists at compile time. This method of implementing inheritance by embedding an anonymous interface or embedding an anonymous pointer object is actually a pure virtual inheritance. What we inherit is only the specification specified by the interface, and the real implementation is injected at runtime. For example, we can analog implementation a gRPC's plugin: // the native gRPC's plugin type Plugin interface { // Name identifies the plugin. Name() string // Init is called once after data structures are built but before // code generation begins. Init(g *Generator) // Generate produces the code generated by the plugin for this file, // except for the imports, by calling the generator's methods // P, In, and Out. Generate(file *FileDescriptor) // GenerateImports produces the import declarations for this file. // It is called after Generate. GenerateImports(file *FileDescriptor) } // custom gRPC's plugin type grpcPlugin struct { *generator.Generator } func (p *grpcPlugin) Name() string { return &quot;grpc&quot; } func (p *grpcPlugin) Init(g *generator.Generator) { p.Generator = g } func (p *grpcPlugin) GenerateImports(file *generator.FileDescriptor) { if len(file.Service) == 0 { return } p.P(`import &quot;google.golang.org/grpc&quot;`) // ... } Go can easily achieve advanced features such as duck object-oriented and virtual inheritance through the combination of several simple features. It is really incredible! ","link":"https://TomorrowTown.github.io/post/go-yu-yan-ji-chu-si-han-shu-fang-fa-he-jie-kou/"},{"title":"Go语言基础(三) -- slice","content":"懒，所以直接贴笔记了 0x00 Simply put, a slice is a simplified version of a dynamic array. Becuase the length of the dynamic array is not fixed, the length of the slice naturally cannot be part of the type. The underlying structure of Go slice is defined in reflect.SliceHeader: type SliceHeader struct { Data uintptr Len int Cap int } Compared with string, the slice has an additional Cap member indicating the maximum capacity of the memory space pointed by the slice(corresponding to the number of elements, not the number of bytes). Figure: The memory structure corresponding to the x := []int{2,3,5,7,11} and y := x[1:3] slice: The way to define slice: var ( a []int // nil slice, equal to nil, generally used to indicate a non-existent slice b = []int{} // empty slice, not equal to nil, generally used to represent a empty collection c = []int{1, 2, 3} // there are 3 elements in the slice, len and cap both are 3 d = c[:2] // there are 2 elements in the slice, len is 2, cap is 3 e = c[0:2:cap(c)] // there are 2 elements in the slice, len is 2, cap is 3 f = c[:0] // there are 0 elements in the slice, len is 0, cap is 3 g = make([]int, 3) // there are 3 elements in the slice, len and cap both are 3 h = make([]int, 2, 3) // there are 2 elements in the slice, len is 2, cap is 3 i = make([]int, 0, 3) // there are 0 elements in the slice, len is 0, cap is 3 ) In addition to traversal, as long as the underlying data pointer, length and capacity of the slice have not changed, the traversal of the slice, the reading and modification of elements are the same as the array. When assigning values or passing parameters to the slice itself, it is similar to the operation of the array pointer, only the slice header information (reflect.SliceHeader) is copied, and the underlying data is not copied. add slice elements The built-in generic function append can append N elements to the end of the slice: var a []int a = append(a, 1) a = append(a, 1, 2, 3) a = append(a, []int{1, 2, 3}...) // append a slice, and the slice need to unpack /* If we need to append a slice to another slice, we must use the ...(ellipsis) operator to tell the Go language to append the slice as multiple separate elements. The element to be appended must be of the same type as the element in the slice. */ However, it should be noted that in the case of insufficient capacity, the append operation will result in reallocation of memory, which may result in huge memory allocation and copy data costs. Even if the capacity is sufficient, you still need to use the return value of the append function to update the slice itself, because the length of the new slice has changed. We can also add elements at the beginning of the slice: var a []int{1, 2, 3} a = append([]int{0}, a) // append a element at the beginning a = append([]int{-1, -2, -3}, a) // append a slice at the beginning At the beginning, it usually causes a reallocation of memory, and causes all existing elements to be copied once. Therefore, the performance of adding elements from the beginning of a slice is generally much worse than the performance of adding elements from the end. Because the append function returns a new slice, that is, it supports chained operations. We can combine multiple append operations to insert elements in the middle of the slice: var a []int a = append(a[:i], append([]int{x}, a[i:]...)...) // insert x at the i position a = append(a[:i], append([]int{1,2,3}, a[i:]...)...) // insert a slice at the i position The second append call in each add operation creates a temporary slice, copies the contents of a[i:] to the newly created slice, and then appends the temporarily created slice to a[: i]. The combination of copy and append can be used to avoid creating intermediate temporary slices, which is also the operation of adding elements: a = append(a, 0) // slice expansion by 1 space copy(a[i+1:], a[i:]) // a[i:] moves backward 1 position a[i] = x // set the newly added elements The combination of copy and append can also be used to insert multiple elements in the middle (that is, insert a slice): a = append(a, x...) // Expand enough space for x slice copy(a[i + len(x):], a[i:]) // a[i:] moves backward len(x) position copy(a[1:], x) // copy the newly added slice delete slice elements There are three cases according to the position of the element to be deleted: delete from the beginning, delete from the middle, and delete from the tail. Among them, deleting the element at the end of the slice is the fastest: a = []int{1, 2, 3} a = a[:len(a)-1] // delete 1 element at the end of the slice a = a[:len(a)-N] // delete N elements at the end of the slice Delete the element at the beginning can move the data pointer directly: a = []int{1, 2, 3} a = a[1:] // delete 1 element at the beginning of the slice a = a[N:] // delete N elements at the beginning of the slice Delete the elements at the beginning can also not move the data pointers, but it will move the following data to the beginning. Can be done in place with append (The so-called in-place completion refers to the completion within the memory interval corresponding to the initial slice data, and will not cause the change of the memory space structure). a = []int{1, 2, 3} a = append(a[:0], a[1:]...) // delete 1 element at the beginning a = append(a[:0], a[N:]...) // delete N element at the beginning Can also use the copy to delete elements at the beginning a = []int{1, 2, 3} a = a[:copy(a, a[1:])] // delete 1 element at the beginning a = a[:copy(a, a[N:])] // delete N elements at the beginning For deleting the middle element, it is necessary to move the remaining elements as a whole, which can also be done in-place with append or copy: a = []int{1, 2, 3} a = append(a[:i], a[i+1:]...) // delete 1 element at the middle a = append(a[:i], a[i+N:]...) // delete N elements at the middle a = a[:i+copy(a[i:], a[i+1:])] // delete 1 element at the middle a = a[:i+copy(a[i:], a[i+N:])]// delete N elements at the middle Slice memory tips For slices, slices with len 0 but cap capacity other than 0 are very useful features. Of course, if both len and cap are 0, it becomes a real empty slice, although it is not a nil slice. When judging whether a slice is empty, it is generally judged by the length of the slice obtained by len. Generally, the slice and the nil value are rarely compared directly. For example, the following TrimSpace function is used to delete the space in []byte. The function implementation takes advantage of the 0-length slice feature, which is efficient and concise. func TrimSpace(s []byte) []byte { b := s[:0] for _, x = range s { if x != ' ' { b = append(b, x) } } return b } In fact, similar algorithms that delete slice elements in-situ according to filter conditions can be handled in a similar method(because the deletion operation will not cause insufficient memory): func Filter(s []byte, fn func(x byte) bool) []byte { b := s[:0] for _, x := range s { if !fn(x) { b = append(b, x) } } return b } The main point of efficient operation of slicing is tovreduce the number of memory allocations, try to ensure that the append operation will not exceed the capacity of the cap, and reduce the number of triggered memory allocations and the size of memory allocated each time. Avoid slice memory leaks The slicing operation does not copy the underlying data. The underlying array will be kept in memory until it is no longer referenced. However, sometimes the entire bottom array may be in use due to a small memory reference, which delays the automatic memory collector's collection of the bottom array. For example, the FindPhoneNumber function loads the entire file into memory, then searches for the first phone number that appears, and finally returns the result in slices. func FindPhoneNumber(filename string) []byte { b, _ := ioutil.ReadFile(filename) return regexp.MustCompile(&quot;[0-9]+&quot;).Find(b) } The []byte returned by this code points to an array that holds the entire file. Because the slice refers to the entire original array, the automatic garbage collector cannot release the space of the underlying array in time. A small requirement may result in the need to save the entire file data for a long time. Although this is not a memory leak in the traditional sense, it may slow down the overall performance of the system. To fix this problem, you can copy the data of interest to a new slice (data transfer is a philosophy of Go programming. Although value transfer has a certain price, the benefit of exchange is to cut off the original data rely): func FindPhoneNumber(filename string) []byte { b, _ := ioutil.ReadFile(filename) b = regexp.MustCompile(&quot;[0-9]+&quot;).Find(b) return append([]byte{}, b...) } Similar problems may be encountered when deleting slice elements. Assuming that the pointer object is stored in the slice, then after deleting the end element, the deleted element is still referenced by the underlying array of the slice, which can not be recycled by the automatic garbage collector in time (this depends on the implementation of the collector): var a []*int{ ... } a = a[:len(a)-1] // the deleted element is still referenced by the underlying array of the slice, which may can not be recycled by the automatic garbage collector in time The insurance method is to first set the elements that need automatic memory recycling to nil to ensure that the automatic collector can find the objects that need to be recycled, and then delete the slices: var a []*int{ ... } a[len(a)-1] = nil // GC recycled the last element's memory a = a[:len(a)-1] // delete the last element in the slice Of course, if the period of slicing is very short, you don't need to deal with this problem. Because if the slice itself can be recycled by GC, each element corresponding to the slice will naturally be recycled. Slice type cast For safety, when the underlying raw slice types of the two slice types []T and []Y are different, Go language cannot directly convert the types. But security comes at a price. Sometimes this conversion has its value-it can simplify coding or improve the performance of the code. For example, on a 64-bit system, a []float64 slice needs to be sorted at high speed, we can force it to be converted to []int integer slice, and then sort by integer (because float64 follows the IEEE754 floating point standard feature, when floating number are ordered, the corresponding integers must also be ordered). The following code converts [] float64 type slices to [] int type slices in two ways: // +build amd64 arm64 import &quot;sort&quot; var a = []float64{4, 2, 5, 7, 2, 1, 88, 1} func SortFloat64FastV1(a []float64) { // type conversion var b []int = ((*[1 &lt;&lt; 20]int)(unsafe.Pointer(&amp;a[0])))[:len(a):cap(a)] // sort the float as int sort.Ints(b) } func SortFloat64FastV2(a []float64) { // Update the slice header information through reflect.SliceHeader to achieve conversion var c []int aHdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;a)) cHdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;c)) *cHdr = *aHdr // sort the float as int sort.Ints(c) } It should be noted that the length of non-zero size arrays in the Go implementation must not exceed 2GB, so the maximum length range of the array must be calculated for the type size of the array elements ([]uint8 maximum 2GB, []uint16 maximum 1GB, and so on, But the length of the [] struct {} array can exceed 2GB). ","link":"https://TomorrowTown.github.io/post/2020-11-29-golang-basics-slice/"},{"title":"Go语言基础(二) -- string","content":"与数组不同，字符串中的元素是不可修改的，字符串是一个只读字节数组。虽然字符串的长度一旦固定就不可修改，但长度并不是字符串类型的一部分。 由于Go的源码需要UTF8编码，所以出现在Go源码中的字符串常量通常是UTF8编码的。 golang中的字符串底层数据结构为reflect.StringHeader： type StringHeader struct { Data uintptr Len int } The string structure consisits of two pieces of information: the first is the underlying byte array pointed by the string, and the second is the length of the string in bytes. The string is actually a structure, so the assignment of the string is the copy process of the reflect.StringHeader structure, and does not involve the copy of the underlying byte array. 字符串结构包含两段信息：第一段是字符串所指向的底层字节数组；第二段是字符串的字节长度。字符串实际上是一个结构，所以字符串的赋值是 reflect.StringHeader结构的拷贝过程，修改赋值后的字符串并不会改变源字符串。 字符串&quot;Hello, World&quot; 对应的内存结构如图： 虽然字符串不是切片，但是也支持针对切片的操作： s := &quot;hello, world&quot; hello := s[:5] world := s[7:] 字符串可以转换成byte[] 和 rune[]，且可使用for range 去遍历字符串。 References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-11-29-golang-basics-string/"},{"title":"游戏开发中的设计模式(一) -- 命令模式","content":"A command is a reified method call. 使用场景示例 输入处理 每个游戏都有一处代码块用来处理用户原始的输入，如：按钮点击、键盘事件、鼠标点击等。 它会记录输入并转换为游戏中的一个动作。 简单实现： void InputHandler::handleInput() { if (isPressed(BUTTON_X)) jump(); else if (isPressed(BUTTON_Y)) fire(); else if (isPressed(BUTTON_A)) swapWeapon(); else if (isPressed(BUTTON_B)) lurchInffectively(); } 上述代码是有效的，但是如今许多游戏允许用户自定义按钮与游戏行为之间的映射关系。 所以，为了支持自定义，我们需要把对jump()、fire()等方法的直接调用转换为可更换的东西。 因此我们需要使用对象来代表一个游戏动作。这就用到了命令模式。 首先，定义一个基类，代表一个可触发的游戏命令： class Command { public: virtual ~Command() {} virtual void execute() = 0; }; 然后为每一个不同的游戏动作创建一个子类： class JumpCmd : public Command { public: virtual void execute() { jump(); } }; class FireCmd : public Command { virtual void execute() { fire(); } }; /// #TODO: add more action subclass . . . 在输入处理中，为每个按钮存储一个指向命令的指针： class InputHandler { public: void handleInput(); /// #TODO: method to bind commands . . . private: Command* button_X; Command* button_Y; Command* button_A; Command* button_B; }; 现在对输入的处理便通过这些指针进行代理： void InputHandler::handleInput() { if (isPressed(BUTTON_X)) button_X-&gt;execute(); else if (isPressed(BUTTON_Y) button_Y-&gt;execute(); else if (isPressed(BUTTON_A) button_A-&gt;execute(); else if (isPressed(BUTTON_B) button_B-&gt;execute(); } 之前每个输入都会直接调用一个函数，现在则增加了一个间接调用层。 解耦角色和命令 在上例中，这些命令的使用范围很窄，只能作用于玩家对象。现在，让我们放宽限制，传入任何一个我们想要控制的对象，而不是让命令自身来确定所控制的对象： class Command { public: virtual ~Command() {} virtual void execute(GameActor&amp; actor) = 0; }; class JumpCmd : public Command { public: virtual void execute(GameActor&amp; actor) { actor.jump(); } }; 接下来修改输入处理方法，使其返回一个命令实例，以便调用具体的execute()： Command* InputHandler::handleInput() { if (isPressed(BUTTON_X)) return button_X; if (isPressed(BUTTON_Y)) return button_Y; if (isPressed(BUTTON_A)) return button_A; if (isPressed(BUTTON_B)) return button_B; return NULL; } 最终，对输入的处理转化为动作的映射代码如下： Command* cmd = inputHandler.handleInput(); if (cmd) { cmd-&gt;execute(actor); } undo&amp;redo 命令模式一个重要的应用就是“撤销操作”。因为命令对象可以do一些事，那么就应该能够轻松地undo它们。这在游戏中应用广泛，比如策略游戏中的回滚操作，以及一些游戏的重播功能。 上述例子中，我们希望从被操控的角色中抽象出命令，以便角色和命令解耦；但在这个例子中，我们希望将命令绑定到被移动的角色上，以便能够实现角色动作的回滚。 示例代码： 封装移动操作： class MoveUnitCmd : public Command { public: MoveUnitCmd(Unit* unit, int x, int y) : mUnit(uint), mX(x), mY(y) {} virtual void execute() { mUnit-&gt;moveTo(mX, mY); } private: Unit* mUnit; int mX; int mY; }; 之前的输入处理程序仅维护单一的命令对象，并在对应按钮被按下时调用其execute()方法。但这里，命令将更加具体，这意味着每次玩家选择一个动作，输入处理程序代码都会创建一个命令实例： Command* handleInput() { Unit* unit = getSelectedUnit(); if (isPressed(BUTTON_UP)) { int destY = unit-&gt;y() - 1; return new MoveUnitCmd(unit, unit-&gt;x(), destY); } if (isPressed(BUTTON_DOWN)) { int destY = unit-&gt;y() + 1; return new MoveUnitCmd(unit, unit-&gt;x(), destY); } /// #TODO: others moves . . . return NULL; } Command类新增undo方法： class Command { public: virtual ~Command() {} virtual void execute() = 0; virtual void undo() = 0; } 进一步，修改上述子类，实现undo方法： class MoveUnitCmd : public Command { public: MoveUnitCmd(Unit* unit, int x, int y) : mUnit(unit), mX(x), mY(y), xBefore(0), yBefore(0), {} virtual void execute() { // remember the unit's position before the move xBefore = mUnit-&gt;x(); yBefore = mUnit-&gt;y(); mUnit-&gt;moveTo(mX, mY); } virtual undo() { mUnit-&gt;moveTo(xBefore, yBefore); } private: Unit* mUnit; int mX, mY; int xBefore, yBefore; } 更进一步，可以支持多次撤销。 具体思路是：不再只保存最后一个命令，而是维护一个命令列表和一个对当前命令的一个引用。当玩家执行了一个命令，就把该命令添加到这个列表，并将当前指针指向它。 当玩家选择undo时，我们撤销当前的命令并将当前指针移回去；当选择redo时，将当前指针移回去，然后从此处开始执行列表中的命令。如果撤销之后选择了一个新命令，则列表中位于当前命令之后的所有命令都被舍弃掉。 References: Game Programming Patterns ","link":"https://TomorrowTown.github.io/post/you-xi-kai-fa-zhong-de-she-ji-mo-shi-yi-ming-ling-mo-shi/"},{"title":"Go语言基础(一) -- array","content":"数组是一种固定长度的序列，可包含0个或多个元素。值得注意的是，长度也是决定数组类型的因素。数组由不同长度或不同类型的数据组成，那么这些数组就是不同的类型，是不能直接赋值的。因此在实际的golang项目中很少使用数组。对应于数组的类型是slice，slice是一种可以动态增长和收缩的序列，本章暂且不表。 var a [3]int // define an int-type array of length 3, all the elements are 0 var b = [...]int{1, 2, 3} // define an int-type array of length 3, elements are 1, 2, 3 var c = [...]int{2: 3, 1: 2} // define an int-type of length 3, elements are 0, 2, 3 var d = [...]int{1, 2, 4: 5, 6} // define an int-type of length 3, elements are 1, 2, 0, 0, 5, 6, /* 值得注意的是第三种和第四种方法去定义一个数组。 第三种方法：golang支持数组中的元素通过索引去初始化，因此初始化时不必按照索引从0开始递增的方式去初始化。数组的长度基于初始化时出现的最大索引，未显式初始化的元素仍然使用0值初始化。 第四种方法：混合了第四种和第三种初始化方法。 */ 内存结构： golang中的数组是值语义的。一个数组变量代表的是整个数组，不像C++，代表的是数组第一个元素的指针。当一个数组被赋值或是被传递，整个数组其实是被拷贝的，修改拷贝的数组并不会改变原数组的数据，因为他们并不共享底层数据结构。 如果数组很大，那么数组分配也会有很大的开销。为了避免复制数组的开销，可以传递一个指向数组的指针，但数组指针不是数组。 var a = [...]int{1, 2, 3} var b = &amp;a fmt.Println(a[0], a[1]) // Prints the first two elements of the array fmt.Println(b[0], b[1]) // Accessing array elements through array pointer is similar to arrays // Iterate through the elements of an array through array pointer. for i, v = range b { ...... } 遍历数组的常用方法 for i := range a { } for i, v := range a { } for i := 0 ; i &lt; len(a); i++ { } 需要注意的是，使用for range的方式进行遍历，其性能要比传统的**for i := 0 ; i &lt; len(a); i++ **要差很多。具体原因请查看：https://www.flysnow.org/2018/10/20/golang-for-range-slice-map.html 数组的其他用途 数组不仅可以用于数字类型，还可以是字符串数组，结构体数组，函数数组，接口数组，管道数组等等： // string array var s1 = [...]string{&quot;hello&quot;, &quot;world&quot;} // structure array var line = [...]image.point{{0, 0}, {1, 1}} // function array var decoder = [...]func(io.Reader) (image.Image, error) { png.Decode, jpeg.Decode, } // interface array var unknown = [...]interface{}{123, &quot;hello&quot;} // pipe array var chanList = [2]chan int{} 也可以定义空数组： var d = [0]int var e = [0]int{} var f = [...]int{} 长度为0的数组不占用内存空间。虽然空数组很少被使用，但它们可以用来强调某些类型的操作，以避免分配额外的内存空间，例如管道同步操作： c1 := make(chan [0]int) go func() { fmt.Println(&quot;c1&quot;) c1 &lt;- [0]int{} }() &lt;- c1 此处我们不关心管道中传输的实际数据类型，管道中的接收和发送操作仅用于消息同步。对于这个应用场景，我们使用一个空数组作为管道类型，以减少分配管道元素的开销。 当然，通常更倾向于使用无类型的匿名结构体以达到相同的目的： c2 := make(chan struct{}) go func() { fmt.Println(&quot;c2&quot;) c2 &lt;- struct{}{} // The part of 'struc{}' means type, and the '{}' represents the value of the structure }() &lt;- c2 在golang中，数组是切片和字符串的基础结构。数组的许多操作都可直接用于切片和字符串。 References: Advanced Go Programming ","link":"https://TomorrowTown.github.io/post/2020-11-12-golang-basics-array/"},{"title":"go服务器性能分析方法","content":"pprof 在需要监测的server源码中的main或init中引入: import _ &quot;net/http/pprof&quot; 启动http监听端口，以此作为性能分析数据展示网页。 go http.ListenAndServe(&quot;:9999&quot;, nil) 这样，默认访问地址为localhost:9999。 无论是否是http服务, 都可以引入net/http/pprof作为性能分析的工具。 go-torch和FlameGraph 安装go-torch和FlameGraph go get github.com/uber/go-torch cd $GOPATH/src/github.com/uber/go-torch git clone https://github.com/brendangregg/FlameGraph.git sudo cp ./FlameGraph/flamegraph.pl /usr/local/bin **NOTE: **go get到的项目默认会放到用户目录下的go文件夹，以此作为该项目的GOPATH。 可能遇到的问题: go get github.com/uber/go-torch时，有可能出现： unrecognized import path &quot;golang.org/x/sys/unix&quot;: https fetch: Get . . . . . . i/o timeout 此时需要: mkdir -p $GOPATH/src/golang.org.x cd $GOPATH/src/golang.org/x git clone https://github.com/golang/sys.git 即可 安装包管理工具 glide用于编译上述下载的go-torch。 go get github.com/Masterminds/glide cd $GOPATH/src/github.com/uber/go-torch glide install 可能遇到的问题: 在glide install时可能出现: 直接无视即可。 运行测试用例 ...... go-torch]$ go test ./... 可能遇到的问题: 出现一堆编译报错。但只要下列语句都没fail, 即可无视其他报错： 最后需要到GOPATH的bin目录下查看是否生成了go-torch可执行文件, 有则成功 运行go-torch获取火焰图 在成功完成了上述所有步骤后，在任意文件夹下都可运行 go-torch命令了。 例： go-torch -u http://localhost:9999 -t 30 -f perf.svg 等待30s，在运行命令的目录下就会生成一份perf.svg（默认是torch.svg）文件, 直接网页打开(实测chome/Edge可正常打开并可点击方块zoom in)该文件即可看到火焰图： 进一步寻找性能痛点 再次用相同的测试条件测试，不过现在仅需要运行： go tool pprof --seconds 60 http://localhost:9999/debug/pprof/profile 60s后会得到cpu分析文件，此时不再是火焰图。 根据之前获得的火焰图，找到不应该占用那么多CPU但是却占用了那么多的方法。 在命令行窗口(pprof)后输入list 方法名， 如果找到了具体哪一步消耗的cpu高，如果该步是另一个包的方法，也无所谓，直接list 方法名即可。 (ps: 输入exit可退出go tool pprof) 会得到该方法中具体哪一步cpu消耗的值，进而得到了该方法的性能痛点。 最后就着手优化吧:) Tips：火焰图中，纵轴从下到上代表调用顺序，横轴每个方块的长度代表占用CPU的时长百分比。 ","link":"https://TomorrowTown.github.io/post/2020-11-05-go-server-performance-analyze/"}]}